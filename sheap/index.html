<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians.">
  <meta name="keywords" content="Gaussian Avatars, Monocular Avatar Reconstruction, Multi-view Diffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-EBQEWD3TX1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-EBQEWD3TX1');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="./static/js/OrbitControls.js"></script>
  <script src="./static/js/verts.js"></script>
  <script src="./static/js/meshes.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://tangjiapeng.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://shenhanqian.github.io/gaussian-avatars/">
              GaussianAvatars
            </a>
            <a class="navbar-item" href="https://tangjiapeng.github.io/projects/GAF/">
              GAF
            </a>
          </div>
        </div>
      </div>
    </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D
              Gaussians</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://nlml.github.io">Liam Schoneveld</a><sup>1</sup>,
                <a href="https://zchen.im/">Zhe Chen</a><sup>1</sup>,
                <a href="https://scholar.google.com/citations?user=PxeB2pEAAAAJ&hl=it">Davide Davoli</a><sup>2</sup>,
                <a href="https://tangjiapeng.github.io">Jiapeng Tang</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Saimon_Terazawa1">Saimon Terazawa</a><sup>1</sup>,
                <a href="https://vision.ist.i.kyoto-u.ac.jp/">Ko Nishino</a><sup>4</sup>
                <a href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias
                  Nie√üner</a><sup>3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Woven by Toyota</span>
              <span class="author-block"><sup>2</sup>Toyota Motor Europe NV/SA</span>
              <!-- <p>
            </p> -->
              <span class="author-block"><sup>3</sup>Technical University of Munich</span>
              <span class="author-block"><sup>4</sup>Kyoto University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2504.12292" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2504.12292" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=vhXsZJWCBMA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- TODO: Code Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/tangjiapeng/GAF"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <table style="width: 100%; table-layout: fixed;">
          <tr>
            <td style="width: 33%; text-align: center;">
              <h3 class="large-text">Input: 2D Image</h3>
            </td>
            <td style="width: 34%; text-align: center;">
              <h3 class="large-text">Predicted Gaussians</h3>
            </td>
            <td style="width: 33%; text-align: center;">
              <h3 class="large-text">Tracked Mesh</h3>
            </td>
          </tr>
        </table>
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <!-- <img src="teaser.png" style="width:100%; margin-right:auto; margin-left:auto; margin-top:auto;"> -->
        <h2 class="subtitle has-text-centered">
          <b>SHeaP</b> learns a state-of-the-art, real-time head geometry predictor through self-supervised learning on
          only 2D videos.
          The key idea is to use 2D Gaussian Splatting instead of mesh rasterization when computing the photometric
          reconstruction loss.
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="container is-max-desktop">
        <div class="column is-full-width">
          <h2 class="title has-text-centered">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Accurate, real-time 3D reconstruction of human heads from monocular images and videos underlies numerous
              visual applications.
              As 3D ground truth data is hard to come by at scale, previous methods have sought to learn from abundant
              2D videos in a self-supervised manner.
              Typically, this involves the use of differentiable mesh rendering, which is effective but faces
              limitations.
              To improve on this, we propose SHeaP (Self-supervised Head Geometry Predictor Learned via 2D Gaussians).
              Given a source image, we predict a 3DMM mesh and a set of Gaussians that are rigged to this mesh.
              We then reanimate this rigged head avatar to match a target frame, and backpropagate photometric losses to
              both the 3DMM and Gaussian prediction networks.
              We find that using Gaussians for rendering substantially improves the effectiveness of this
              self-supervised approach.
              Training solely on 2D data, our method surpasses existing self-supervised approaches in geometric
              evaluations on the NoW benchmark for neutral faces and a new
              benchmark for non-neutral expressions.
              Our method also produces highly expressive meshes, outperforming state-of-the-art in emotion
              classification.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="container is-max-desktop">
        <div class="column is-full-width">
          <h2 class="title has-text-centered">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/vhXsZJWCBMA" frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen=""></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>

  <section class="section">
    <!-- Method Overview. -->
    <div class="container is-max-desktop">
      <div class="column is-full-width">
        <h2 class="title has-text-centered">Method Overview</h2>
        <img src="./static/images/method.png" style="width:100%; margin-right:auto; margin-left:auto; margin-top:auto;">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
          integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
          integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
          crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
          integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
          onload="renderMathInElement(document.body);"></script>

        <div class="content has-text-justified">
          <p>
            At each training step, we sample a source image \( I_\textit{source} \) and a target image \(
            I_\textit{target} \).
            These are both passed through the same vision transformer (ViT), which predicts 3DMM parameters shape \(
            \bm{\beta} \) , pose \( \bm{\theta} \) and expression \( \bm{\psi} \) , plus an environment lighting latent
            \( \bm{\ell} \) and identity features \( \bm{f} \).
            A Gaussians Regressor takes \( \bm{f} \) as input, along with DINOv2 features \( \mathbf{d} \)
            The Gaussians Regressor predicts a set of Gaussians \( \mathcal{G} \) , which are bound to the predicted
            3DMM mesh and rendered with 2DGS to produce \( \hat{I}_\textit{target} \)
            Finally, photometric losses between \( \hat{I}_\textit{target} \) and \( I_\textit{target} \) are
            backpropagated to the ViT and Gaussians Regressor parameters, as well as additional losses based on rendered
            depth, normals, and landmarks

          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <!-- Interactive Results. -->
    <div class="container is-max-desktop">
      <h2 class="title has-text-centered">Interactive Results</h2>
      <div style="overflow: hidden; display: flex; justify-content: center;">
        <div class="container" style="overflow: hidden; width: max-content; display: inline-block;">
          <div id="post_images" class="carousel">
            <div class="item-1">
              <div class="gallery-item">
                <img src="./static/images/gallery/image2.jpg" alt="Input Image" style="float: left;">
                <div id="viewer2" style="width: 50%; float: right;"></div>
              </div>
            </div>
            <div class="item-2">
              <div class="gallery-item">
                <img src="./static/images/gallery/image1.jpg" alt="Input Image" style="float: left;">
                <div id="viewer1" style="width: 50%; float: right;"></div>
              </div>
            </div>
            <div class="item-3">
              <div class="gallery-item">
                <img src="./static/images/gallery/image3.jpg" alt="Input Image" style="float: left;">
                <div id="viewer3" style="width: 50%; float: right;"></div>
              </div>
            </div>
            <div class="item-4">
              <div class="gallery-item">
                <img src="./static/images/gallery/image4.jpg" alt="Input Image" style="float: left;">
                <div id="viewer4" style="width: 50%; float: right;"></div>
              </div>
            </div>
            <div class="item-5">
              <div class="gallery-item">
                <img src="./static/images/gallery/image5.jpg" alt="Input Image" style="float: left;">
                <div id="viewer5" style="width: 50%; float: right;"></div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="content center has-text-centered">
        <p>
          Click and drag to rotate the 3D mesh. Use the scroll wheel to zoom in and out.
        </p>
      </div>
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title has-text-centered">Comparisons Versus Baselines</h2>
      <div style="overflow:hidden;">
        <div class="container">
          <div id="post_images" class="carousel">
            <div class="item-1">
              <video autoplay loop muted controls webkit-playsinline playsinline
                style="pointer-events: none; width:100%;">
                <source src="./static/videos/compare/0_Clip+1qf8dZpLED0+P2+C1+F5731-5855_v2_compressed.mp4"
                  type="video/mp4">
              </video>
            </div>
            <div class="item-2">
              <video autoplay loop muted controls webkit-playsinline playsinline
                style="pointer-events: none; width:100%;">
                <source src="./static/videos/compare/1_Clip+RfHY644z7aI+P0+C1+F2537-2828_v2_compressed.mp4"
                  type="video/mp4">
              </video>
            </div>
            <div class="item-3">
              <video autoplay loop muted controls webkit-playsinline playsinline
                style="pointer-events: none; width:100%;">
                <source src="./static/videos/compare/2_Clip+x9klsDwglJM+P0+C1+F3802-3955_v2_compressed.mp4"
                  type="video/mp4">
              </video>
            </div>
            <div class="item-4">
              <video autoplay loop muted controls webkit-playsinline playsinline
                style="pointer-events: none; width:100%;">
                <source src="./static/videos/compare/3_Clip+syGpm7DM-4g+P3+C2+F20443-20604_v2_compressed.mp4"
                  type="video/mp4">
              </video>
            </div>
            <div class="item-5">
              <video autoplay loop muted controls webkit-playsinline playsinline
                style="pointer-events: none; width:100%;">
                <source src="./static/videos/compare/4_Clip+okx7B5ggBvo+P0+C0+F3046-3157_v2_compressed.mp4"
                  type="video/mp4">
              </video>
            </div>
            <div class="item-6">
              <video autoplay loop muted controls webkit-playsinline playsinline
                style="pointer-events: none; width:100%;">
                <source src="./static/videos/compare/5_Clip+v5GmF7zLPCo+P0+C2+F1874-2015_v2_compressed.mp4"
                  type="video/mp4">
              </video>
            </div>
          </div>
          <table style="width: 100%; table-layout: fixed;">
            <tr>
              <td style="width: 20%; text-align: center;">
                <h3 class="large-text">DECA</h3>
              </td>
              <td style="width: 20%; text-align: center;">
                <h3 class="large-text">EMOCA</h3>
              </td>
              <td style="width: 20%; text-align: center;">
                <h3 class="large-text">SMIRK</h3>
              </td>
              <td style="width: 20%; text-align: center;">
                <h3 class="large-text">SHeaP (ours)</h3>
              </td>
              <td style="width: 20%; text-align: center;">
                <h3 class="large-text">Input</h3>
              </td>
            </tr>
          </table>
        </div>
        <div class="content has-text-justified">
          <p>
            Compared to state-of-the-art methods, our approach reconstructs more accurate head geometry with better
            temporal stability.
            It also produces less exaggerated expressions than EMOCA or SMIRK, and accurately models the neck joint.
          </p>
        </div>
        <!-- End Hero Carousel -->
        <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>
        <script>
          bulmaCarousel.attach('#post_images', {
            slidesToScroll: 1,
            slidesToShow: 1,
            loop: true,
          });
        </script>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{schoneveld2025sheap,
  title={SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians},
  author={Schoneveld, Liam and Chen, Zhe and Davoli, Davide and Tang, Jiapeng and Terazawa, Saimon and Nishino, Ko and Nie√üner, Matthias},
  booktitle={arxiv},
  year={2025}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/abs/2504.12292">
          <i class="fas fa-file-pdf"></i>
        </a>
        <!-- <a class="icon-link" href="https://github.com/tangjiapeng/GAF" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a> -->
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Website source code is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>